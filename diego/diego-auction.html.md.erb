---
title: How Diego Allocates Work
---

The Diego Auction is the process by which [Diego](./diego-architecture.html) allocates tasks and long running processes (LRPs) to [Cells](./diego-components.html#cell-components), which execute them. The auction replaces the [Cloud Controller DEA placement algorithm](../architecture/cloud-controller.html#dea-placement), which performed this function in the pre-Diego Cloud Foundry architecture.

[Auction on GitHub](https://github.com/cloudfoundry-incubator/auction)

##<a id='processes'></a>Tasks and Long Running Processes

Diego runs and monitors two types of processes: **Tasks** and **Long Running Processes** (LRPs). 

* <a id='task'></a>**Tasks**: Tasks run once, for a finite amount of time.
   
    Example Tasks: Making a database schema change, bulk importing data to initialize a database, setting up a connected service

* <a id='lrp'></a>**Long Running Processes** (LRPs): LRPs run continuously, for an indefinite time. LRPs only terminate if stopped or killed, or in the case of failure. Diego can run multiple instances of any LRP.
    
	Example LRPs: A web-server, a service that continuously accepts input and processes it, an application

##<a id='initiate'></a>Initiating an Auction

An [Auctioneer](./diego-components.html#auctioneer) initiates an auction when it receives a request to allocate a batch of work (tasks and LRPs) either from:

- A Cell [Rep](./diego-components.html#rep), in response to a request from the Cloud Controller via the CC-Bridge.

- The [Converger](./diego-components.html#converger), in response to a mismatch between the desired LRPs and actual LRPs as represented in the BBS(./diego-components.html#bbs).

Only one auction can take place at a time.

##<a id='fetch-info'></a>Querying the Cells

The Auctioneer queries the state of each Cell via a request to the Cell [Rep](./diego-components.html#rep). The information provided by the Rep includes:

- the Cell's available capacity
- the Cell's stack
- the set of Actual LRPs currently running on the Cell

##<a id='prioritizing'></a>Prioritizing the Work to be Auctioned

When the Auctioneer receives a batch of work it must strategically decide the order in which to distributed it. 

Two pitfalls must be avoided: 

* The Auctioneer could incorrectly fill the Cells with small units of work before attempting to place large units of work. As a result, these large units could fail to place even if there is sufficient capacity in the cluster. 

* The Auctioneer could incorrectly prioritize large units of work over small units of work. As a result, each Cell could be filled with a single large app, preventing smaller apps from having any instances running.

To avoid these bad results, the Auctioneer first sorts the batch of LRPs to allocate into priority groups based on their global indices. Each LRP has an index for its type, which is unique across a deployment. Within each priority group, work is sorted in order of decreasing memory demand so that larger units of work are placed first.

For example, suppose a batch contains the following 5 LRPS:

<table border='1' class='nice'>
	<tr>
		<th>LRP type</th>
		<th>LRP index</th>
	</tr>
		<td>type 1</td>
		<td>0</td>
	<tr>
		<td>type 1</td>
		<td>1</td>
	</tr>
		<td>type 1</td>
		<td>2</td>
	<tr>
		<td>type 2</td>
		<td>0</td>
	</tr>
	<tr>
		<td>type 2</td>
		<td>1</td>
	</tr>
</table>

The Auctioneer would allocate the LRPs in the following order:

* Type 1/ Index 0
* Type 2/ Index 0
* Type 1/ Index 1
* Type 2/ Index 1
* Type 1/ Index 2

This sorting by index ensures that LRPs of each type are placed before all of the LRPs of any type are, preventing both large and small LRPs from dominating the allocation process.

##<a id='allocating'></a>Allocating Work

The Auctioneer calculates the distribution of Actual LRPs across available Cells.

For each Task and LRP in the batch, The Auctioneer does the following:

1. It filters the pool of candidate cells to those with the correct stack and sufficient resources to host the actual LRP.

1. It chooses the winning cell by optimizing for the following, in increasing priority:
	1. an even distribution of memory, disk, and container usage across Cells (all with equal weighting)
	1. minimizing colocation of ActualLRP instances of a given DesiredLRP on the same Cell (takes precedence over the distribution of memory/disk/etc.).
	1. minimizing colocation of ActualLRP instances of a given DesiredLRP in the same Availability Zone

After calculating the distribution of Tasks and LRPs to Cells, the Auctioneer submits requests to the Cells to execute their allotted work.

Any work that could not be allocated is carried over into the next batch.

If a Cell responds by saying the work can not be performed, the Auctioneer carries the failed work over into the next batch.

If a Cell fails to respond, for example if a connection times out, the Auctioneer does *not* carry the work over into the next batch. In this case the Auctioneer defers to the Converger to figure out what to do.

Any work carried over into the next batch is merged with work that came in during the previous auction, and the loop is repeated.
