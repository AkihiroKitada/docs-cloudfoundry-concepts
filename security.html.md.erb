---
title: Understanding Cloud Foundry Security
owner: Security
---

<strong><%= modified_date %></strong>

<%=vars.pcf_rec%> protects customers from security threats by minimizing network surface area, applying security controls, isolating customer applications and data in containers, and encrypting connections.


Cloud Foundry:

* Implements role-based access controls, applying and enforcing roles and permissions to ensure that users can only view and affect the spaces for which they have been granted access.

* Ensures security of application bits in a multi-tenant environment.

* Prevents possible denial of service attacks through resource starvation.

Before you read this document, you might want to review the [general system architecture](./architecture/index.html).

## <a id='system-boundaries'></a>System Boundaries and Access ##

As the image below shows, in a typical deployment of Cloud Foundry, the components run on virtual machines (VMs) that exist within a VLAN. In this configuration, the only access points visible on a public network are a load balancer that maps to one or more Cloud Foundry routers and, optionally, a NAT VM and a jumpbox. Because of the limited number of contact points with the public internet, the surface area for possible security vulnerabilities is minimized.

<p class="note"><strong>Note</strong>: <%=vars.pcf_rec%> recommends that you also install a NAT VM for outbound requests and a jumpbox to access the BOSH Director, though these access points are optional depending on your network configuration.</p>

  <%= image_tag("images/security/sysbound1.png") %>

### <a id='protocols'></a>Protocols ###

All traffic from the public internet to the Cloud Controller and UAA happens over HTTPS. Inside the boundary of the system, components communicate over a publish-subscribe (pub-sub) message bus, [NATS](http://nats.io/), and also HTTP.

### <a id='bosh'></a>BOSH ###

Operators deploy Cloud Foundry with BOSH. The BOSH Director is the core orchestrating component in BOSH: it controls VM creation and deployment, as well as other software and service lifecycle events. You use HTTPS to ensure secure communication to the BOSH Director.

<p class="note"><strong>Note</strong>: <%=vars.pcf_rec%> recommends that you deploy the BOSH Director on a subnet that is not publicly accessible, and access the BOSH Director from a jumpbox on the subnet or through VPN.</p>

BOSH includes the following functionality for security:

* Communicates with the VMs it launches over NATS. Because NATS cannot be accessed from outside Cloud Foundry, this ensures that published messages can only originate from a component within your deployment.

* Provides an audit trail through the `bosh tasks` command. This command shows all actions that an operator has taken with BOSH.

* Allows you to set up individual login accounts for each operator. BOSH operators have root access.

<p class="note"><strong>Note</strong>: BOSH does not encrypt data stored on BOSH VMs. Your IaaS might encrypt this data.</p>

## <a id='auth'></a>Authentication and Authorization ##

[User Account and Authentication](./architecture/uaa.html) (UAA) is the central identity management service for the Elastic Runtime platform and its various components.

UAA acts as an [OAuth2](https://oauth.io/) Authorization Server and issues access tokens for applications that request platform resources. The tokens are based on the [JSON Web Token](http://jwt.io/) and are digitally signed by UAA.

Operators can configure the identity store in UAA. If users register an account with the Cloud Foundry platform, UAA acts as the user store and stores user passwords in the UAA database using [bcrypt](http://en.wikipedia.org/wiki/Bcrypt). UAA also supports connecting to external user stores through LDAP and SAML. Once an operator has configured the external user store, such as a corporate Microsoft Active Directory, users can use their LDAP credentials to gain access to the Cloud Foundry platform instead of registering a separate account. Alternatively, operators can use SAML to connect to an external user store and enable single sign-on for users into the Cloud Foundry platform.

### <a id='rbac'></a>Managing User Access with Role-Based Access Control ###

Applications that users deploy to Cloud Foundry exist within a space. Spaces exist within orgs. To view and access an org or a space, a user must be a member of it. Cloud Foundry uses role-based access control (RBAC), with each role granted permissions to either an org or a specified space. For more information about roles and permissions, refer to the [Orgs, Spaces, Roles, and Permissions](roles.html) topic.

<%=vars.console_links%>

## <a id='containers'></a>Application Isolation with Containers ##

Each application deployed to Cloud Foundry runs within its own self-contained environment, a [Garden container](./diego/diego-architecture.html#garden) that isolates processes, memory, and the file system.  Cloud Foundry operators can configure whether contained applications can directly interact with other applications or other Cloud Foundry system components.

Applications are typically allowed to invoke other applications in Cloud Foundry only by leaving the system and re-entering through the load balancer positioned in front of the Cloud Foundry routers. To isolate applications and control outgoing traffic, each Garden container uses a dedicated virtual network interface (VNI) that consists of a pair of ethernet addresses, one visible to the application instance running in the container, and the other visible to the host VM’s root namespace. The pair is configured to use IPs in a small and static subnet.

This restrictive operating environment is designed for security and stability. If a spoofing attack bypasses the physical firewall for your deployment, Cloud Foundry <%=vars.net_traffic_rules%> help prevent the attack from accessing application containers.

### <a id='application-traffic'></a>Application Traffic ###

When an app instance starts, the cell (or DEA) on the host VM allocates an IP address and also assigns an arbitrary port to the application container. The application uses the `PORT` environment variable provided in the container environment to determine which port to listen on. Because the host assigns a random value to the `PORT` environment variable, the value is generally unique for each application instance.

A host VM has a single IP address. If you configure the deployment with the cluster on a VLAN, as recommended, then all traffic goes through the following levels of network address translation, as shown in the diagram below:

* <strong>Inbound</strong> requests flow from the load balancer through the router to the host cell (or DEA), then into the app container. The router determines which application instance receives each request.

* <strong>Outbound</strong> traffic flows from the app container to the cell (or DEA), then to the gateway on the cell's virtual network interface. This gateway might be a NAT to external networks depending on your IaaS.

  <%= image_tag("images/security/sysbound2.png") %>


### <a id='network-traffic'></a>Network Traffic Rules ###

Administrators can configure rules to prevent system access from external networks and between internal components, and to restrict applications from establishing connections over the virtual network interface.
Admins can configure these rules at two levels. Application Security Groups apply <%=vars.net_traffic_rules%> at the container level, and Network Properties of cells (or DEAs) apply them at the host VM level.

#### <a id='container-rules'></a>Application Security Groups ####

To target applications with specific network traffic rules, <%=vars.app_sec_groups%> (ASGs) define traffic rules for individual containers. The rules specify the protocols, addresses, and ports that are allowed for outgoing traffic. Because they are “allow” rules, their order of evaluation is unimportant when multiple application security groups apply to the same space, org, or deployment. The cell uses these rules to filter and log outbound network traffic.

When applications are first staging, they need traffic rules loose enough to let them pull resources in from across the network. Once they are running, the traffic rules can be more restrictive and secure. To distinguish between these two security needs, admins can define one ASG for when an app stages, and a different one for when it runs.

To provide granular control in securing a deployment, an administrator can assign ASGs to apply across a Cloud Foundry deployment, or to specific spaces or orgs within a deployment. You define ASGs on the cf CLI using `cf create-security-group` and `cf bind-security-group`. <%=vars.manifest_vs_cli_asg%>

#### <a id='container-rules'></a>Host-level Network Properties ####

Operators can configure the `allow_networks` and `deny_networks` parameters for DEAs to restrict communication between system components and applications. Any Cloud Foundry ASG configurations will overwrite these configurations. For more information, see <%=vars.dea_properties%>.

<p class="note"><strong>Note</strong>: <%=vars.pcf_rec%> recommends that you use Cloud Foundry ASGs to specify egress access rules for your applications. This functionality enables you to more securely restrict application outbound traffic to predefined routes.</p>

### <a id='filesystem'></a>Container Mechanics###

Container isolation is achieved by namespacing kernel resources that would otherwise be shared. The intended level of isolation is set such that multiple containers present on the same host cannot detect each other. Every container includes a private root filesystem – each container has its own Process ID (PID), namespace, network namespace, and mount namespace.

This container filesystem is created by stacking a read-only base filesystem and a container-specific read-write filesystem, commonly known as an overlay filesystem. The read-only filesystem contains the minimal set of operating system packages and Garden-specific modifications common to all containers. Containers can share the same read-only base filesystem because all writes are applied to the read-write filesystem. The read-write filesystem is unique to each container and is created by formatting a large sparse file of a fixed size. This fixed size prevents the read-write filesystem from overflowing into unallocated space.

Resource control is managed using Linux control groups ([cgroups](https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt)) or Windows [job objects](https://msdn.microsoft.com/en-us/library/windows/desktop/ms684161(v=vs.85).aspx). Associating each container with its own cgroup or job object limits the amount of memory that the container may use. Linux cgroups also require the container to use a fair share of CPU compared to the relative CPU share of other containers. 

<p class="note">
    <strong>Note</strong>: BOSH does not support a RedHat Enterprise Linux OS stemcell. This is due to an inherent security issue with the way RedHat handles user namespacing and container isolation.
</p>

## <a id='service-broker'></a>Security for Service Broker Integration ##

The Cloud Controller authenticates every request with the Service Broker API using HTTP or HTTPS, depending on which protocol that you specify during broker registration. The Cloud Controller rejects any broker registration that does not contain a username and password.

Service instances bound to an app contain credential data. Users specify the binding credentials for [user-provided service instances](../devguide/services/user-provided.html), while third-party brokers specify the binding credentials for managed service instances. The VCAP_SERVICES environment variable contains credential information for any service bound to an app. Cloud Foundry constructs this value from encrypted data that it stores in the Cloud Controller Database (CCDB).

<p class="note"><strong>Note</strong>: The selected third-party broker controls how securely to communicate managed service credentials.</p>

A third-party broker might offer a dashboard client in its catalog. Dashboard clients require a text string defined as a `client_secret`. Cloud Foundry does not store this secret in the CCDB. Instead, Cloud Foundry passes the secret to the UAA component for verification using HTTP or HTTPS.

## <a id='vuln-manage'></a>Software Vulnerability Management ##

Cloud Foundry manages software vulnerability using releases and BOSH stemcells. New Cloud Foundry releases are created with updates to address code issues, while new stemcells are created with patches for the latest security fixes to address any underlying operating system issues.

## <a id='app-artifacts'></a>Ensuring Security for Application Artifacts ##

Cloud Foundry secures both the code and the configuration of an application using the following functionality:

* Application developers push their code using the [Cloud Foundry API](http://apidocs.cloudfoundry.org/). Cloud Foundry secures each call to the CF API using the [UAA](#auth) and SSL.

* The Cloud Controller uses [RBAC](#rbac) to ensure that only authorized users can access a particular application.

* The Cloud Controller stores the configuration for an application in an encrypted database table. This configuration data includes user-specified environment variables and service credentials for any services bound to the app.

* Cloud Foundry runs the app inside a secure container. For more information, see the [Application Isolation with Containers](#containers) section.

* Cloud Foundry operators can configure network traffic rules to control inbound communication to and outbound communication from an app. For more information, see the [Network Traffic Rules](#network-traffic) section.

## <a id='logging'></a>Security Event Logging and Auditing ##

For operators, Cloud Foundry provides an audit trail through the `bosh tasks` command. This command shows all actions that an operator has taken with the platform.
Additionally, operators can redirect Cloud Foundry component logs to a standard syslog server using the `syslog_daemon_config` [property](http://docs.cloudfoundry.org/running/managing-cf/logging.html) in the `metron_agent` job of `cf-release`.

For users, Cloud Foundry records an audit trail of all relevant API invocations of an app. The CLI command `cf events` returns this information.

## <a id='recommendations'></a>Recommendations for Running a Secure Deployment ##

To help run a secure deployment, <%=vars.pcf_rec%> recommends the following:

* Configure UAA clients and users using a BOSH manifest. Limit and manage these clients and users as you would any other kind of privileged account.

* Deploy within a VLAN that limits network traffic to individual VMs. This reduce the possibility of unauthorized access to the VMs within your BOSH-managed cloud.

* Enable HTTPS for applications and SSL database connections to protect sensitive data transmitted to and from applications.

* Ensure that the jumpbox is secure, along with the load balancer and NAT VM.

* Encrypt stored files and data within databases to meet your data security requirements. Deploy using industry standard encryption and the best practices for your language or framework.

* Prohibit promiscuous network interfaces on the trusted network.

* Review and monitor data sharing and security practices with third-party services that you use to provide additional functionality to your application.

* Store SSH keys securely to prevent disclosure, and promptly replace lost or compromised keys.

* Use Cloud Foundry’s RBAC model to restrict your users' access to only what is necessary to complete their tasks.

* Use a strong passphrase for both your Cloud Foundry user account and SSH keys.
